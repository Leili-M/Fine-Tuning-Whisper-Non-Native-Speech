<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Fine-Tuning Whisper Â· Speechocean762</title>
  <meta name="description" content="Fine-tuning Whisper-tiny.en on Speechocean762 for non-native & child speech ASR. Full methodology, results, and analysis." />
  <meta name="theme-color" content="#0f172a" />
  <style>
    /* RESET */
    *,*::before,*::after{box-sizing:border-box} html,body{margin:0;padding:0} img{max-width:100%;display:block}
    a{color:inherit;text-decoration:none}

    /* THEME */
    :root{
      --bg:#0b1020; --bg-soft:#0e1530; --fg:#e8ecf3; --muted:#a6b0c3;
      --primary:#60a5fa; --primary-2:#34d399;
      --card:#0f172a; --surface:#101a33; --border:#1e293b;
      --radius:16px; --radius-sm:12px; --shadow:0 12px 40px rgba(0,0,0,.35);
      --max: 980px;
      --glass: linear-gradient(180deg, rgba(255,255,255,.06), rgba(255,255,255,.02));
      --glass-border: 1px solid rgba(255,255,255,.10);
    }
    @media (prefers-color-scheme: light){
      :root{
        --bg:#f7f9fc; --bg-soft:#eef2f7; --fg:#0f172a; --muted:#475569;
        --primary:#2563eb; --primary-2:#059669;
        --card:#ffffff; --surface:#ffffff; --border:#e5e7eb;
        --shadow:0 12px 40px rgba(2,6,23,.10);
        --glass: linear-gradient(180deg, rgba(0,0,0,.03), rgba(0,0,0,.00));
        --glass-border: 1px solid rgba(15,23,42,.08);
      }
    }
    body{
      font-family: ui-sans-serif, system-ui, -apple-system, "Segoe UI", Roboto, "Helvetica Neue", Arial;
      background:
        radial-gradient(1200px 600px at 10% -20%, rgba(37,99,235,.18), transparent 55%),
        radial-gradient(900px 500px at 110% 10%, rgba(52,211,153,.18), transparent 55%),
        var(--bg);
      color:var(--fg); letter-spacing:.2px;
    }

    /* HERO */
    .hero{position:relative;overflow:hidden;padding:64px 16px 36px;border-bottom:1px solid var(--border);
      background:linear-gradient(135deg, rgba(37,99,235,.25), rgba(2,6,23,.0) 45%),
                 radial-gradient(700px 280px at 95% -20%, rgba(52,211,153,.25), transparent 60%);}
    .hero__inner{max-width:var(--max);margin:0 auto}
    .brand{display:flex;align-items:center;gap:.8rem;margin-bottom:14px;font-weight:800;font-size:1.05rem}
    .logo{width:40px;height:40px;border-radius:12px;display:grid;place-items:center;
      background:linear-gradient(135deg,var(--primary),var(--primary-2));color:#fff;box-shadow:var(--shadow)}
    .title{font-size:clamp(1.7rem,2.8vw+1.1rem,2.6rem);line-height:1.15;margin:8px 0 8px;font-weight:900}
    .subtitle{color:var(--muted);max-width:800px;font-size:1.05rem}
    .meta{margin-top:16px;display:flex;gap:.6rem;flex-wrap:wrap}
    .pill{padding:.32rem .7rem;border-radius:999px;background:var(--glass);border:var(--glass-border);backdrop-filter:blur(10px);-webkit-backdrop-filter:blur(10px);color:var(--fg);font-size:.85rem}

    /* LAYOUT */
    main{max-width:var(--max);margin:0 auto;padding:28px 16px 72px}
    .grid{display:grid;grid-template-columns:1fr;gap:22px}
    @media (min-width:960px){.grid{grid-template-columns:260px 1fr}.sidebar{position:sticky;top:18px}}

    /* CARDS (glassy) */
    .card{border-radius:var(--radius);background:var(--glass);border:var(--glass-border);
      box-shadow:var(--shadow);backdrop-filter:blur(12px);-webkit-backdrop-filter:blur(12px)}
    .pad{padding:18px}

    /* TOC */
    .toc h3{margin:.2rem 0 .6rem;font-size:.95rem;color:var(--muted)}
    .toc a{display:block;padding:.5rem .6rem;border-radius:10px}
    .toc a:hover{background:rgba(255,255,255,.06)}
    .toc a.active{background:rgba(96,165,250,.18);color:var(--primary)}

    /* CONTENT */
    section{scroll-margin-top:84px}
    h2{font-size:1.35rem;margin:10px 0 8px}
    h3{font-size:1.05rem;margin:12px 0 6px}
    p{margin:.4rem 0 1rem} ul{margin:.2rem 0 1rem 1.2rem} li{margin:.28rem 0}
    .note{color:var(--muted);font-size:.95rem}
    .hr{height:1px;background:var(--border);margin:22px 0}

    /* TABLE */
    .table-wrap{overflow:auto;border-radius:12px;border:var(--glass-border)}
    table{width:100%;border-collapse:collapse;min-width:620px;background:var(--surface)}
    th,td{padding:.8rem .75rem;border-bottom:1px solid var(--border);text-align:left}
    th{position:sticky;top:0;background:var(--surface);font-weight:700}

    /* KPI */
    .kpi{display:grid;gap:12px;grid-template-columns:repeat(auto-fit,minmax(210px,1fr));margin:10px 0 16px}
    .kpi .item{border:var(--glass-border);border-radius:14px;padding:14px;background:var(--surface)}
    .kpi .label{font-size:.82rem;color:var(--muted)} .kpi .val{font-size:1.25rem;font-weight:800}

    /* FIGURES */
    .figure{display:grid;gap:10px}
    .figure img{border-radius:14px;box-shadow:var(--shadow);border:var(--glass-border)}
    .figcap{font-size:.92rem;color:var(--muted);text-align:center}
    .gallery{display:flex;flex-wrap:wrap;gap:14px;justify-content:center}
    .gallery img{width:320px;border-radius:12px;box-shadow:var(--shadow);border:var(--glass-border)}
    footer{max-width:var(--max);margin:0 auto;padding:20px 16px 48px;color:var(--muted);font-size:.95rem;text-align:center}
  </style>
  <script>
    // TOC active link + smooth scroll
    document.addEventListener('DOMContentLoaded', () => {
      const links=[...document.querySelectorAll('.toc a')];
      const ids=links.map(a=>document.querySelector(a.getAttribute('href'))).filter(Boolean);
      const io=new IntersectionObserver((entries)=>{
        entries.forEach(e=>{
          const idx=ids.indexOf(e.target);
          if(idx>=0 && e.isIntersecting){ links.forEach(l=>l.classList.remove('active')); links[idx].classList.add('active'); }
        });
      },{rootMargin:'-60% 0px -35% 0px', threshold:.01});
      ids.forEach(el=>io.observe(el));
      document.addEventListener('click', (e)=>{
        const a=e.target.closest('a[href^="#"]'); if(!a) return;
        const el=document.querySelector(a.getAttribute('href')); if(!el) return;
        e.preventDefault(); el.scrollIntoView({behavior:'smooth'}); history.pushState(null,'',a.getAttribute('href'));
      });
    });
  </script>
</head>
<body>
  <!-- HERO -->
  <div class="hero">
    <div class="hero__inner">
      <div class="brand">
        <div class="logo" aria-hidden="true">ðŸŽ§</div>
        <div>Fine-Tuning Whisper</div>
      </div>
      <div class="title">Fine-Tuning Whisper for Non-Native & Child Speech Recognition</div>
      <p class="subtitle">
        Adapting <strong>Whisper (tiny.en)</strong> to <strong>Speechocean762</strong> for better ASR on <em>non-native</em> & <em>child</em> speech.
      </p>
      <div class="meta">
        <span class="pill">WER: 65.4% â†’ <strong>21.7%</strong></span>
        <span class="pill">Validation loss: 1.66 â†’ <strong>0.49</strong></span>
        <span class="pill">GPU: T4 Â· ~1.5h</span>
      </div>
    </div>
  </div>

  <!-- LAYOUT -->
  <main>
    <div class="grid">
      <!-- SIDEBAR -->
      <aside class="sidebar card pad toc">
        <h3>On this page</h3>
        <a href="#overview">Overview</a>
        <a href="#objectives">Project Objectives</a>
        <a href="#why">Why Whisper?</a>
        <a href="#dataset">Dataset</a>
        <a href="#methodology">Methodology</a>
        <a href="#results">Results</a>
        <a href="#qualitative">Qualitative Analysis</a>
        <a href="#fluency">Fluency Evaluation</a>
        <a href="#discussion">Discussion</a>
        <a href="#conclusion">Conclusion</a>
      </aside>

      <!-- CONTENT -->
      <article class="content">
        <section id="overview" class="card pad">
          <h2>Overview</h2>
          <p>This project fine-tunes OpenAIâ€™s <strong>Whisper (tiny.en)</strong> on <strong>Speechocean762</strong> to improve ASR for <em>non-native</em> and <em>child</em> speech.</p>
          <p>We quantify gains via WER and analyze behavior across fluency levels; training used 600 steps with TensorBoard monitoring.</p>
        </section>

        <section id="objectives" class="card pad">
          <h2>Project Objectives</h2>
          <ul>
            <li>Adapt Whisper for non-native & child speech.</li>
            <li>Provide a reproducible fine-tuning pipeline.</li>
            <li>Measure WER improvement and relate loss â†” WER.</li>
            <li>Qualitatively compare transcripts before/after fine-tuning.</li>
          </ul>
        </section>

        <section id="why" class="card pad">
          <h2>Why Whisper?</h2>
          <ul>
            <li><strong>Pretrained:</strong> ~680k hours multilingual data.</li>
            <li><strong>Efficient:</strong> <code>tiny.en</code> ~39M params â†’ fast iteration.</li>
            <li><strong>English-focused:</strong> strong baseline for adaptation.</li>
          </ul>
        </section>

        <section id="dataset" class="card pad">
          <h2>Dataset: Speechocean762</h2>
          <ul>
            <li><strong>Domain:</strong> English from non-native speakers (adults + children).</li>
            <li><strong>Traits:</strong> high phonetic/prosodic diversity; balanced gender/age/fluency.</li>
          </ul>
        </section>

        <section id="methodology" class="card pad">
          <h2>Methodology</h2>

          <h3>Data Preparation</h3>
          <ul>
            <li>Log-Mel spectrograms via Whisper feature extractor.</li>
            <li>Lowercasing & basic normalization of transcripts.</li>
            <li>Text tokenization to label IDs.</li>
          </ul>
          <p class="note">This matches Whisperâ€™s encoderâ€“decoder pipeline.</p>

          <h3>Model & Training</h3>
          <div class="kpi">
            <div class="item"><div class="label">Trainer</div><div class="val">Seq2SeqTrainer</div></div>
            <div class="item"><div class="label">LR</div><div class="val">1e-5</div></div>
            <div class="item"><div class="label">Batch</div><div class="val">8 / device</div></div>
            <div class="item"><div class="label">Warmup</div><div class="val">500</div></div>
            <div class="item"><div class="label">Max steps</div><div class="val"><strong>600</strong></div></div>
            <div class="item"><div class="label">Loss</div><div class="val">Cross-Entropy</div></div>
            <div class="item"><div class="label">Metric</div><div class="val">WER</div></div>
          </div>
          <div class="note"><strong>Why CE instead of WER?</strong> WER is discrete/non-differentiable; CE is differentiable and trains reliably while WER is tracked for eval.</div>
        </section>

        <section id="results" class="card pad">
          <h2>Results</h2>

          <div class="kpi">
            <div class="item"><div class="label">Training Steps</div><div class="val">600</div></div>
            <div class="item"><div class="label">Validation Loss</div><div class="val">1.66 â†’ <strong>0.49</strong></div></div>
            <div class="item"><div class="label">WER (%)</div><div class="val">65.4 â†’ <strong>21.7</strong></div></div>
            <div class="item"><div class="label">Duration</div><div class="val">~1.5h (T4)</div></div>
          </div>

          <div class="table-wrap" style="margin-top:8px">
            <table>
              <thead><tr><th>Metric</th><th>Baseline (tiny.en)</th><th>Fine-tuned</th></tr></thead>
              <tbody>
                <tr><td><strong>Training Steps</strong></td><td>â€“</td><td><strong>600</strong></td></tr>
                <tr><td><strong>Validation Loss</strong></td><td>1.66</td><td><strong>0.49</strong> (stable)</td></tr>
                <tr><td><strong>WER (%)</strong></td><td>65.4</td><td><strong>21.7</strong> (~67% â†“)</td></tr>
                <tr><td><strong>Duration</strong></td><td>â€“</td><td>~1.5h (T4)</td></tr>
              </tbody>
            </table>
          </div>

          <div class="hr"></div>
          <h3>Training Loss & WER â€” Combined Plot</h3>

          <!-- ONE combined image for all three charts -->
          <figure class="figure" aria-label="Combined training/eval curves">
            <img src="metrics_combined.png" alt="Combined curves: eval loss, eval WER, train loss over 600 steps" />
            <figcaption class="figcap">
              Combined TensorBoard export (3 panels): leftâ€”eval loss, middleâ€”eval WER, rightâ€”train loss.  
              Eval loss reached ~0.49 and WER ~21.3â€“21.7% around step ~600; curves are smooth and parallel â†’ no overfitting.
            </figcaption>
          </figure>

          <!-- OPTIONAL: fallback gallery for separate images (delete if unused) -->
          <!--
          <div class="gallery" style="margin-top:10px">
            <img src="eval_loss.png" alt="Eval loss curve" />
            <img src="eval_wer.png"  alt="Eval WER curve" />
            <img src="train_loss.png" alt="Train loss curve" />
          </div>
          -->

          <h3>Interpretation</h3>
          <ul>
            <li>Fast loss drop in first ~150 steps; then gradual convergence.</li>
            <li>Best WER ~21.3â€“21.7% near step 600.</li>
            <li>Parallel train/val loss trends indicate good generalization without overfitting.</li>
          </ul>
        </section>

        <section id="qualitative" class="card pad">
          <h2>Qualitative Analysis</h2>
          <p>Representative fixes after fine-tuning:</p>
          <div class="table-wrap">
            <table>
              <thead><tr><th>Type</th><th>Reference</th><th>Baseline</th><th>Fine-tuned</th></tr></thead>
              <tbody>
                <tr><td>Normal</td><td>he likes the famous city sydney</td><td>my like</td><td><strong>he likes the famous city sydney</strong></td></tr>
                <tr><td>Non-native</td><td>we eat less meat</td><td>we less meat</td><td><strong>we eat less meat</strong></td></tr>
                <tr><td>Longer</td><td>i will bring the yellow bag tomorrow</td><td>i bring the bag</td><td><strong>i will bring the yellow bag tomorrow</strong></td></tr>
              </tbody>
            </table>
          </div>
        </section>

        <section id="fluency" class="card pad">
          <h2>Fluency Evaluation</h2>
          <ul>
            <li>Largest gains on <em>low-fluency</em> utterances (baseline had most errors).</li>
            <li>Even high-fluency speakers improved a few points.</li>
            <li>Generalization improved across articulation rates & accent intensity.</li>
          </ul>
        </section>

        <section id="discussion" class="card pad">
          <h2>Discussion</h2>
          <div class="table-wrap">
            <table>
              <thead><tr><th>Aspect</th><th>Insight</th></tr></thead>
              <tbody>
                <tr><td><strong>Loss Function</strong></td><td>WER canâ€™t train directly; CE enables stable optimization.</td></tr>
                <tr><td><strong>Behavior</strong></td><td>Loss and WER both improved consistently.</td></tr>
                <tr><td><strong>Generalization</strong></td><td>Validation trends mirror training â†’ no overfitting.</td></tr>
                <tr><td><strong>Efficiency</strong></td><td>Notable gains with just <strong>600 steps</strong> on a T4.</td></tr>
              </tbody>
            </table>
          </div>
        </section>

        <section id="conclusion" class="card pad">
          <h2>Conclusion</h2>
          <p>Fine-tuning Whisper on Speechocean762 significantly improves ASR for non-native & child speech. With only <strong>600 steps</strong>, WER dropped by ~<strong>67%</strong> relative.</p>
          <ul>
            <li>Small models can be highly effective with domain adaptation.</li>
            <li>Loss reduction correlates with accuracy gains.</li>
            <li>Whisper adapts well with limited compute/data.</li>
          </ul>
          <p style="text-align:center;margin-top:8px"><a href="#overview" class="pill">â†‘ Back to top</a></p>
        </section>
      </article>
    </div>
  </main>

  <footer>
    Â© <span id="y"></span> Â· Fine-Tuning Whisper Â· Built for GitHub Pages
  </footer>
  <script>document.getElementById('y').textContent=new Date().getFullYear()</script>
</body>
</html>
